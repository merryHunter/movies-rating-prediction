{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cde53c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.53.1-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (2.5.1+cu124)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (0.27.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
      "Downloading transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, hf-xet, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.27.1\n",
      "    Uninstalling huggingface-hub-0.27.1:\n",
      "      Successfully uninstalled huggingface-hub-0.27.1\n",
      "Successfully installed hf-xet-1.1.5 huggingface-hub-0.33.2 regex-2024.11.6 sentence-transformers-5.0.0 tokenizers-0.21.2 transformers-4.53.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615f3e7",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "Though we have GPU power, but as we have quite short text fields, we will rather use sentence transformer, also for making experiments quicker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0723a8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device='cuda')\n",
    "model.half()\n",
    "embeddings = model.encode(sentences)\n",
    "print(len(embeddings[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c5e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_csv(\"../data/filtered/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32cfbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tagline and description into one text field\n",
    "df = df.with_columns(\n",
    "    pl.concat_str(pl.col('tagline'), pl.col('description'), separator=' ').alias('text')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cda4ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "baea0c79",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearRegression' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text_list \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m----> 2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m(text_list)\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m      4\u001b[0m     pl\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, embeddings\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearRegression' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "text_list = df['text'].to_list()\n",
    "embeddings = model.encode(text_list)\n",
    "df = df.with_columns(\n",
    "    pl.Series(\"text_embeddings\", embeddings.tolist()[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67b18a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 1000004,\n",
       " 'Fight Club',\n",
       " 1999,\n",
       " 'Mischief. Mayhem. Soap.',\n",
       " 'A ticking-time-bomb insomniac and a slippery soap salesman channel primal male aggression into a shocking new form of therapy. Their concept catches on, with underground \"fight clubs\" forming in every town, until an eccentric gets in the way and ignites an out-of-control spiral toward oblivion.',\n",
       " 139,\n",
       " 'R',\n",
       " 4.27,\n",
       " 'Mischief. Mayhem. Soap. A ticking-time-bomb insomniac and a slippery soap salesman channel primal male aggression into a shocking new form of therapy. Their concept catches on, with underground \"fight clubs\" forming in every town, until an eccentric gets in the way and ignites an out-of-control spiral toward oblivion.',\n",
       " [-0.06121826171875,\n",
       "  -0.00634765625,\n",
       "  -0.004726409912109375,\n",
       "  0.008453369140625,\n",
       "  0.01248931884765625,\n",
       "  -0.0006728172302246094,\n",
       "  0.1322021484375,\n",
       "  0.0238189697265625,\n",
       "  -0.027557373046875,\n",
       "  -0.0201873779296875,\n",
       "  0.0129547119140625,\n",
       "  -0.0163726806640625,\n",
       "  0.0278778076171875,\n",
       "  0.04541015625,\n",
       "  -0.033050537109375,\n",
       "  0.00836181640625,\n",
       "  0.01219940185546875,\n",
       "  -0.0477294921875,\n",
       "  0.01149749755859375,\n",
       "  0.031524658203125,\n",
       "  -0.022979736328125,\n",
       "  0.046173095703125,\n",
       "  0.0095367431640625,\n",
       "  -0.0577392578125,\n",
       "  -0.09637451171875,\n",
       "  0.09271240234375,\n",
       "  0.026824951171875,\n",
       "  0.0119171142578125,\n",
       "  -0.0231170654296875,\n",
       "  -0.031280517578125,\n",
       "  0.053009033203125,\n",
       "  0.08404541015625,\n",
       "  -0.0225982666015625,\n",
       "  -0.049774169921875,\n",
       "  -0.041015625,\n",
       "  -0.0310211181640625,\n",
       "  0.032989501953125,\n",
       "  -0.00049591064453125,\n",
       "  0.12371826171875,\n",
       "  0.051361083984375,\n",
       "  -0.038116455078125,\n",
       "  -0.0533447265625,\n",
       "  -0.014434814453125,\n",
       "  -0.042816162109375,\n",
       "  -0.0280303955078125,\n",
       "  -0.05889892578125,\n",
       "  0.08123779296875,\n",
       "  -0.032623291015625,\n",
       "  0.0050811767578125,\n",
       "  -0.03729248046875,\n",
       "  0.0272369384765625,\n",
       "  -0.039337158203125,\n",
       "  0.01041412353515625,\n",
       "  0.03289794921875,\n",
       "  0.052398681640625,\n",
       "  -0.1182861328125,\n",
       "  0.021026611328125,\n",
       "  0.075927734375,\n",
       "  -0.0396728515625,\n",
       "  0.050262451171875,\n",
       "  0.032012939453125,\n",
       "  0.053192138671875,\n",
       "  0.057708740234375,\n",
       "  0.0767822265625,\n",
       "  0.0230560302734375,\n",
       "  0.01239013671875,\n",
       "  0.038238525390625,\n",
       "  0.1453857421875,\n",
       "  -0.001689910888671875,\n",
       "  -0.0149078369140625,\n",
       "  -0.050872802734375,\n",
       "  -0.07855224609375,\n",
       "  0.0189361572265625,\n",
       "  0.011199951171875,\n",
       "  0.02471923828125,\n",
       "  0.021759033203125,\n",
       "  -0.037811279296875,\n",
       "  -0.033599853515625,\n",
       "  -0.00936126708984375,\n",
       "  -0.086181640625,\n",
       "  -0.02508544921875,\n",
       "  0.0340576171875,\n",
       "  -0.047637939453125,\n",
       "  0.0286712646484375,\n",
       "  -0.003948211669921875,\n",
       "  -0.0224609375,\n",
       "  0.01971435546875,\n",
       "  -0.004306793212890625,\n",
       "  0.11285400390625,\n",
       "  0.039093017578125,\n",
       "  -0.132568359375,\n",
       "  0.0246124267578125,\n",
       "  0.04168701171875,\n",
       "  0.0022068023681640625,\n",
       "  -0.0008559226989746094,\n",
       "  0.0100860595703125,\n",
       "  -0.04351806640625,\n",
       "  -0.057952880859375,\n",
       "  -0.0989990234375,\n",
       "  0.1165771484375,\n",
       "  -0.0733642578125,\n",
       "  0.059722900390625,\n",
       "  -0.047607421875,\n",
       "  -0.049835205078125,\n",
       "  0.065673828125,\n",
       "  -0.047149658203125,\n",
       "  0.00289154052734375,\n",
       "  0.0240631103515625,\n",
       "  0.025115966796875,\n",
       "  0.03863525390625,\n",
       "  -0.0292510986328125,\n",
       "  -0.0231781005859375,\n",
       "  0.01123046875,\n",
       "  -0.0229949951171875,\n",
       "  0.05279541015625,\n",
       "  -0.021270751953125,\n",
       "  -0.01544189453125,\n",
       "  0.01727294921875,\n",
       "  -0.0467529296875,\n",
       "  0.050933837890625,\n",
       "  0.150634765625,\n",
       "  -0.021881103515625,\n",
       "  -0.09222412109375,\n",
       "  0.0628662109375,\n",
       "  0.005115509033203125,\n",
       "  0.0114898681640625,\n",
       "  -0.052215576171875,\n",
       "  0.0,\n",
       "  0.033843994140625,\n",
       "  -0.0016469955444335938,\n",
       "  -0.059783935546875,\n",
       "  0.04315185546875,\n",
       "  0.038604736328125,\n",
       "  0.0160675048828125,\n",
       "  0.01210784912109375,\n",
       "  -0.040618896484375,\n",
       "  -0.01001739501953125,\n",
       "  0.11175537109375,\n",
       "  -0.0005879402160644531,\n",
       "  0.0222320556640625,\n",
       "  -0.0009527206420898438,\n",
       "  0.0244140625,\n",
       "  0.03179931640625,\n",
       "  0.039764404296875,\n",
       "  -0.0148468017578125,\n",
       "  0.0182037353515625,\n",
       "  0.0037822723388671875,\n",
       "  -0.0965576171875,\n",
       "  -0.026641845703125,\n",
       "  0.07080078125,\n",
       "  -0.04888916015625,\n",
       "  -0.0745849609375,\n",
       "  -0.070068359375,\n",
       "  0.03472900390625,\n",
       "  -0.01558685302734375,\n",
       "  0.0292205810546875,\n",
       "  0.1170654296875,\n",
       "  0.03448486328125,\n",
       "  0.0011892318725585938,\n",
       "  0.0106658935546875,\n",
       "  0.0224609375,\n",
       "  0.051971435546875,\n",
       "  0.005764007568359375,\n",
       "  -0.0163116455078125,\n",
       "  -0.11669921875,\n",
       "  -0.0841064453125,\n",
       "  -0.003803253173828125,\n",
       "  0.039947509765625,\n",
       "  -0.1348876953125,\n",
       "  -0.0038509368896484375,\n",
       "  -0.01458740234375,\n",
       "  0.038299560546875,\n",
       "  -0.0450439453125,\n",
       "  0.0653076171875,\n",
       "  -0.04754638671875,\n",
       "  0.0179901123046875,\n",
       "  -0.06707763671875,\n",
       "  -0.0657958984375,\n",
       "  -0.0008287429809570312,\n",
       "  0.017822265625,\n",
       "  0.07269287109375,\n",
       "  0.056610107421875,\n",
       "  -0.03173828125,\n",
       "  0.0262298583984375,\n",
       "  -0.046112060546875,\n",
       "  -0.02362060546875,\n",
       "  -0.0579833984375,\n",
       "  0.0711669921875,\n",
       "  0.035552978515625,\n",
       "  -0.0002720355987548828,\n",
       "  -0.066650390625,\n",
       "  -0.0367431640625,\n",
       "  -0.0009527206420898438,\n",
       "  -0.089599609375,\n",
       "  0.04693603515625,\n",
       "  0.052459716796875,\n",
       "  -0.00933837890625,\n",
       "  0.01436614990234375,\n",
       "  -0.036224365234375,\n",
       "  0.08258056640625,\n",
       "  -0.01617431640625,\n",
       "  -0.022674560546875,\n",
       "  -0.039703369140625,\n",
       "  -0.07989501953125,\n",
       "  0.10333251953125,\n",
       "  -0.0276336669921875,\n",
       "  -0.04461669921875,\n",
       "  -0.04315185546875,\n",
       "  -0.0267791748046875,\n",
       "  -0.087158203125,\n",
       "  0.033599853515625,\n",
       "  0.049346923828125,\n",
       "  -0.07806396484375,\n",
       "  0.00676727294921875,\n",
       "  0.01690673828125,\n",
       "  -0.01001739501953125,\n",
       "  -0.058685302734375,\n",
       "  -0.0004930496215820312,\n",
       "  -0.0014886856079101562,\n",
       "  -0.049835205078125,\n",
       "  0.041900634765625,\n",
       "  0.0185089111328125,\n",
       "  -0.06268310546875,\n",
       "  0.0,\n",
       "  0.048675537109375,\n",
       "  -0.035003662109375,\n",
       "  -0.1285400390625,\n",
       "  -0.01371002197265625,\n",
       "  0.086669921875,\n",
       "  0.029571533203125,\n",
       "  -0.01702880859375,\n",
       "  0.0767822265625,\n",
       "  -0.04949951171875,\n",
       "  0.0197296142578125,\n",
       "  -0.09759521484375,\n",
       "  -0.02520751953125,\n",
       "  -0.038909912109375,\n",
       "  -0.03131103515625,\n",
       "  0.1304931640625,\n",
       "  -0.06500244140625,\n",
       "  0.048492431640625,\n",
       "  0.007770538330078125,\n",
       "  0.034271240234375,\n",
       "  0.041259765625,\n",
       "  0.10125732421875,\n",
       "  0.0087127685546875,\n",
       "  -0.043304443359375,\n",
       "  -0.09014892578125,\n",
       "  0.029815673828125,\n",
       "  0.01273345947265625,\n",
       "  0.01303863525390625,\n",
       "  0.0648193359375,\n",
       "  -0.10540771484375,\n",
       "  0.11737060546875,\n",
       "  0.021636962890625,\n",
       "  0.0183868408203125,\n",
       "  -0.0213775634765625,\n",
       "  -0.05517578125,\n",
       "  -0.036895751953125,\n",
       "  0.07464599609375,\n",
       "  0.00972747802734375,\n",
       "  -0.12469482421875,\n",
       "  -0.0655517578125,\n",
       "  -0.0902099609375,\n",
       "  -0.07281494140625,\n",
       "  0.0237579345703125,\n",
       "  -0.0035839080810546875,\n",
       "  0.108154296875,\n",
       "  -0.021148681640625,\n",
       "  0.07171630859375,\n",
       "  -0.06097412109375,\n",
       "  0.059814453125,\n",
       "  -0.00537872314453125,\n",
       "  -0.0006270408630371094,\n",
       "  0.01433563232421875,\n",
       "  0.04046630859375,\n",
       "  0.03411865234375,\n",
       "  -0.0357666015625,\n",
       "  -0.03338623046875,\n",
       "  0.0181121826171875,\n",
       "  -0.01800537109375,\n",
       "  -0.076904296875,\n",
       "  -0.044769287109375,\n",
       "  0.05096435546875,\n",
       "  -0.03802490234375,\n",
       "  0.029510498046875,\n",
       "  -0.08868408203125,\n",
       "  0.1260986328125,\n",
       "  -0.051513671875,\n",
       "  -0.061065673828125,\n",
       "  -0.053009033203125,\n",
       "  -0.04083251953125,\n",
       "  -0.038787841796875,\n",
       "  -0.020843505859375,\n",
       "  0.06610107421875,\n",
       "  -0.018768310546875,\n",
       "  -0.00516510009765625,\n",
       "  -0.078369140625,\n",
       "  -0.0016736984252929688,\n",
       "  -0.0065460205078125,\n",
       "  -0.005084991455078125,\n",
       "  -0.053497314453125,\n",
       "  -0.022796630859375,\n",
       "  -0.027435302734375,\n",
       "  0.022979736328125,\n",
       "  -0.00787353515625,\n",
       "  0.03857421875,\n",
       "  0.075439453125,\n",
       "  -0.0872802734375,\n",
       "  0.0133514404296875,\n",
       "  -0.0142669677734375,\n",
       "  0.10113525390625,\n",
       "  0.04718017578125,\n",
       "  0.0179290771484375,\n",
       "  0.048614501953125,\n",
       "  -0.0279388427734375,\n",
       "  0.002750396728515625,\n",
       "  0.026824951171875,\n",
       "  0.042938232421875,\n",
       "  -0.0,\n",
       "  -0.0245513916015625,\n",
       "  -0.014892578125,\n",
       "  -0.021026611328125,\n",
       "  0.0218353271484375,\n",
       "  0.10009765625,\n",
       "  0.076171875,\n",
       "  -0.08984375,\n",
       "  0.0914306640625,\n",
       "  0.01230621337890625,\n",
       "  -0.0005750656127929688,\n",
       "  0.0159759521484375,\n",
       "  -0.03515625,\n",
       "  0.050811767578125,\n",
       "  0.003742218017578125,\n",
       "  0.01544952392578125,\n",
       "  0.0052642822265625,\n",
       "  0.0501708984375,\n",
       "  0.0059051513671875,\n",
       "  -0.09796142578125,\n",
       "  -0.02642822265625,\n",
       "  0.0076446533203125,\n",
       "  -0.061126708984375,\n",
       "  0.025390625,\n",
       "  -0.03662109375,\n",
       "  -0.00748443603515625,\n",
       "  -0.03204345703125,\n",
       "  -0.045989990234375,\n",
       "  -0.040740966796875,\n",
       "  -0.0156707763671875,\n",
       "  0.028411865234375,\n",
       "  -0.01342010498046875,\n",
       "  -0.01128387451171875,\n",
       "  -0.0177154541015625,\n",
       "  0.00908660888671875,\n",
       "  -0.056121826171875,\n",
       "  0.08880615234375,\n",
       "  -0.03240966796875,\n",
       "  -0.062255859375,\n",
       "  0.004184722900390625,\n",
       "  0.005916595458984375,\n",
       "  -0.0310516357421875,\n",
       "  0.0017366409301757812,\n",
       "  0.0662841796875,\n",
       "  0.01485443115234375,\n",
       "  0.0110931396484375,\n",
       "  -0.040863037109375,\n",
       "  -0.0020351409912109375,\n",
       "  -0.043487548828125,\n",
       "  0.0567626953125,\n",
       "  -0.07379150390625,\n",
       "  0.01395416259765625,\n",
       "  0.00135040283203125,\n",
       "  0.0268402099609375,\n",
       "  0.004924774169921875,\n",
       "  0.07373046875,\n",
       "  -0.03460693359375,\n",
       "  -0.041259765625,\n",
       "  0.050933837890625,\n",
       "  -0.0506591796875,\n",
       "  0.06488037109375,\n",
       "  -0.00341796875,\n",
       "  0.04083251953125,\n",
       "  0.0081939697265625,\n",
       "  -0.0138397216796875])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.row(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "593f321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.filter(pl.col('date') < 2015)\n",
    "df_val = df.filter(pl.col('date') >= 2015)\n",
    "\n",
    "X_train = df_train.select('text_embeddings').to_numpy()\n",
    "y_train = df_train.select('rating').to_numpy()\n",
    "\n",
    "X_val = df_val.select('text_embeddings').to_numpy()\n",
    "y_val = df_val.select('rating').to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "484edfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9094, 384)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [x[0] for x in X_train]\n",
    "X_test = [x[0] for x in X_val]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d92b050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.27)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cfdb56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.5764623933833773\n",
      "Ridge Regression RMSE: 0.5763471346635302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=0.1),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    print(f\"{model_name} RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862231c5",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "text only model performs worse than numerical model (lacks more context about movie)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37443ad4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
